{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"chapter1/","text":"Prompt Foundations & OpenPages Integration Goals: - Understand prompt engineering basics - Run a simple prompt in the watsonx.ai UI 1.1 What Is a Prompt? A prompt is a textual instruction (plus context and variables) you send to a foundation model to elicit desired output. A well\u2011designed prompt includes: Context / system instructions Clear task instructions Variable placeholders (e.g. {{Text}} ) Output format constraints (e.g. JSON schema, headings) Error / fallback handling 1.2 PII Redaction Example Let's jump over to watsonx.ai and start prompting!","title":"Overview"},{"location":"chapter1/#prompt-foundations-openpages-integration","text":"Goals: - Understand prompt engineering basics - Run a simple prompt in the watsonx.ai UI","title":"Prompt Foundations &amp; OpenPages Integration"},{"location":"chapter1/#11-what-is-a-prompt","text":"A prompt is a textual instruction (plus context and variables) you send to a foundation model to elicit desired output. A well\u2011designed prompt includes: Context / system instructions Clear task instructions Variable placeholders (e.g. {{Text}} ) Output format constraints (e.g. JSON schema, headings) Error / fallback handling","title":"1.1 What Is a Prompt?"},{"location":"chapter1/#12-pii-redaction-example","text":"Let's jump over to watsonx.ai and start prompting!","title":"1.2 PII Redaction Example"},{"location":"chapter2/0_index/","text":"Lab 1: Integrating a Custom ML Model for Risk Classification in OpenPages This lab walks through how to configure and use the Custom Machine Learning Models feature in IBM OpenPages 9.x to automatically classify risk descriptions into your two\u2011level taxonomy. You will: Set up and deploy the prompt in Prompt Lab Configure a connection to your deployed model Map input fields Map output fields and JSONata expressions Configure user guidance Add the model to a view Test the integration Prerequisites & Notes - You must have Custom Machine Learning Models permission in OpenPages, otherwise the menu is not visible. - You must have watsonx.ai","title":"Overview"},{"location":"chapter2/0_index/#lab-1-integrating-a-custom-ml-model-for-risk-classification-in-openpages","text":"This lab walks through how to configure and use the Custom Machine Learning Models feature in IBM OpenPages 9.x to automatically classify risk descriptions into your two\u2011level taxonomy. You will: Set up and deploy the prompt in Prompt Lab Configure a connection to your deployed model Map input fields Map output fields and JSONata expressions Configure user guidance Add the model to a view Test the integration Prerequisites & Notes - You must have Custom Machine Learning Models permission in OpenPages, otherwise the menu is not visible. - You must have watsonx.ai","title":"Lab 1: Integrating a Custom ML Model for Risk Classification in OpenPages"},{"location":"chapter2/1_wxai/","text":"Lab 1.1: Creating and Deploying a model in watsonx.ai 1. Set Up and Deploy the prompt in Prompt Lab Create a new Prompt Lab asset in your project. Craft your prompt, with reference to what bits of information will be coming from the object you want the AI feature on. Add this as a variable in the prompt. Save the prompt as a prompt template. Promote asset to deployment space. Deploy asset in deployment space. Note down the deployment ID. We will need this in OpenPages.","title":"Creating the model"},{"location":"chapter2/1_wxai/#lab-11-creating-and-deploying-a-model-in-watsonxai","text":"","title":"Lab 1.1: Creating and Deploying a model in watsonx.ai"},{"location":"chapter2/1_wxai/#1-set-up-and-deploy-the-prompt-in-prompt-lab","text":"Create a new Prompt Lab asset in your project. Craft your prompt, with reference to what bits of information will be coming from the object you want the AI feature on. Add this as a variable in the prompt. Save the prompt as a prompt template. Promote asset to deployment space. Deploy asset in deployment space. Note down the deployment ID. We will need this in OpenPages.","title":"1. Set Up and Deploy the prompt in Prompt Lab"},{"location":"chapter2/2_op_integration/","text":"Lab 1.2: Integrate the model in OpenPages 1. Access the Custom Machine Learning Models Configuration Log in to OpenPages as an admin (with required permissions). From the Administration menu, go to Integrations \u2192 Custom Machine Learning Models . Click New Model to begin configuring a new integration. 2. Configure Model Access / Connection On the \u201cNew Model\u201d screen: Enter Name and Label (e.g. risk_classification ) Select the AI Service Type (e.g. Watson Machine Learning on IBM Cloud) Enter Access Parameters such as: Watson service type: Watson Machine Learning on Cloud Authentication URL: https://iam.cloud.ibm.com/identity/token API Key: Retrieve from IBM Cloud Base Deployment URL: https://us-south.ml.cloud.ibm.com/ml/v4 Deployment ID: Retrieve from deployment space on watsonx.ai Space ID: Retrieve from model/prompt template deployment on watsonx.ai API version: 2021-05-01 Click Test Connection to verify connectivity Generating your watsonx API key for OpenPages: - Go to ibm - Via the tool bar, go to Manage > Acces (IAM) Create a new API Key that will be used for inferencing from OpenPages Copy the new API Key to enter into the \"New Model\" sceen. Make sure you keep this key a secret. After entering valid details, click Next to proceed. 3. Map the Inputs (Model \u2192 OpenPages fields) On the Map Inputs page: Choose the Object Type (Risk) to which this model applies. Decide whether input is Manual or Automatic mapping. Add one row per input your model expects: Model input field (must match the name used by your deployed model, e.g. risk_description ) Select the corresponding OpenPages field (e.g. Description ) Mark whether the input is Required Click Next to move to output mapping. (If \u201cNext\u201d is disabled, check that at least one input row is defined.) 4. Map the Outputs and JSONata Extraction On the Map Outputs page: Select the Insight type , e.g. Set fields (because you want the model to populate the Level 1 / Level 2 fields) Choose whether each output is Single insight or List of insights (for your taxonomy, Single is typical) :contentReference[oaicite:3]{index=3} For each output you want (e.g. Level\u202f1 classification, Level\u202f2 classification): Output label (e.g. PrimaryClassification , SecondaryClassification ) JSONata expression to extract the value from the model\u2019s JSON response Example: if model\u2019s JSON is: { \"level_1_classification\": \"Clients Products and Business Practices\", \"level_2_classification\": \"Product Flaws\" } then JSONata expressions might be: level_1_classification level_2_classification If the response is wrapped (e.g. under results.generated_text ), you may need results.generated_text.level_1_classification (If Insight type = Set fields) Target field : map the output to your OpenPages enumerated field Optionally set Confidence score or Minimum confidence thresholds if your scenario requires filtering suggestions. (If using Set fields ) choose whether suggestions are User set or Automatically set . Click Next to proceed to guidance configuration. 5. Configure User Guidance and Display On the Guidance page: Enter a Description explaining what the model does (e.g. \u201cThis model classifies text into risk taxonomy\u201d) Optionally set Notification Messages or Style / display options for how users see the model\u2019s suggestion. Optional: you can embed JSONata-based conditions for alerts. Click Save to complete model setup. The model should now appear in the Custom Machine Learning Models table with status \u201cComplete\u201d.","title":"Integrate the model in OpenPages"},{"location":"chapter2/2_op_integration/#lab-12-integrate-the-model-in-openpages","text":"","title":"Lab 1.2: Integrate the model in OpenPages"},{"location":"chapter2/2_op_integration/#1-access-the-custom-machine-learning-models-configuration","text":"Log in to OpenPages as an admin (with required permissions). From the Administration menu, go to Integrations \u2192 Custom Machine Learning Models . Click New Model to begin configuring a new integration.","title":"1. Access the Custom Machine Learning Models Configuration"},{"location":"chapter2/2_op_integration/#2-configure-model-access-connection","text":"On the \u201cNew Model\u201d screen: Enter Name and Label (e.g. risk_classification ) Select the AI Service Type (e.g. Watson Machine Learning on IBM Cloud) Enter Access Parameters such as: Watson service type: Watson Machine Learning on Cloud Authentication URL: https://iam.cloud.ibm.com/identity/token API Key: Retrieve from IBM Cloud Base Deployment URL: https://us-south.ml.cloud.ibm.com/ml/v4 Deployment ID: Retrieve from deployment space on watsonx.ai Space ID: Retrieve from model/prompt template deployment on watsonx.ai API version: 2021-05-01 Click Test Connection to verify connectivity Generating your watsonx API key for OpenPages: - Go to ibm - Via the tool bar, go to Manage > Acces (IAM) Create a new API Key that will be used for inferencing from OpenPages Copy the new API Key to enter into the \"New Model\" sceen. Make sure you keep this key a secret. After entering valid details, click Next to proceed.","title":"2. Configure Model Access / Connection"},{"location":"chapter2/2_op_integration/#3-map-the-inputs-model-openpages-fields","text":"On the Map Inputs page: Choose the Object Type (Risk) to which this model applies. Decide whether input is Manual or Automatic mapping. Add one row per input your model expects: Model input field (must match the name used by your deployed model, e.g. risk_description ) Select the corresponding OpenPages field (e.g. Description ) Mark whether the input is Required Click Next to move to output mapping. (If \u201cNext\u201d is disabled, check that at least one input row is defined.)","title":"3. Map the Inputs (Model \u2192 OpenPages fields)"},{"location":"chapter2/2_op_integration/#4-map-the-outputs-and-jsonata-extraction","text":"On the Map Outputs page: Select the Insight type , e.g. Set fields (because you want the model to populate the Level 1 / Level 2 fields) Choose whether each output is Single insight or List of insights (for your taxonomy, Single is typical) :contentReference[oaicite:3]{index=3} For each output you want (e.g. Level\u202f1 classification, Level\u202f2 classification): Output label (e.g. PrimaryClassification , SecondaryClassification ) JSONata expression to extract the value from the model\u2019s JSON response Example: if model\u2019s JSON is: { \"level_1_classification\": \"Clients Products and Business Practices\", \"level_2_classification\": \"Product Flaws\" } then JSONata expressions might be: level_1_classification level_2_classification If the response is wrapped (e.g. under results.generated_text ), you may need results.generated_text.level_1_classification (If Insight type = Set fields) Target field : map the output to your OpenPages enumerated field Optionally set Confidence score or Minimum confidence thresholds if your scenario requires filtering suggestions. (If using Set fields ) choose whether suggestions are User set or Automatically set . Click Next to proceed to guidance configuration.","title":"4. Map the Outputs and JSONata Extraction"},{"location":"chapter2/2_op_integration/#5-configure-user-guidance-and-display","text":"On the Guidance page: Enter a Description explaining what the model does (e.g. \u201cThis model classifies text into risk taxonomy\u201d) Optionally set Notification Messages or Style / display options for how users see the model\u2019s suggestion. Optional: you can embed JSONata-based conditions for alerts. Click Save to complete model setup. The model should now appear in the Custom Machine Learning Models table with status \u201cComplete\u201d.","title":"5. Configure User Guidance and Display"},{"location":"chapter2/3_view_customisation/","text":"Lab 1.3: Making the AI feature available in OpenPages 1. Add the Model to a View The AI model now must be integrated into the view of where we want to interact with it. We want this model on the Risk object so we must navigate to the relevant view. Go to any risk and then turn on debug info via the Administration Menu. The view will then appear beneath the risk heading. Navigate to the view to customize it by clicking on the view name. In the view designer for your object (e.g. Risk view), find the option to add the View AI insight button and drag it into the area on the view in which you want to be able to interact with it. For this use-case, we will add it to the Risk Categorisation area. Add the relevant details to the button parameters to connect your model Save or Publish the view so the model is active in that view. 2. Test the Model in OpenPages Navigate to a Risk record in the view where the model is active. Fill in the description (or whatever text triggers the model). A lightbulb / insight icon should appear indicating the model can run (or automatically run). Click on it and observe the side panel with model output suggestions (for Level\u202f1 and Level\u202f2). Validate whether the classifications match expectations. Test edge cases (no clear classification, ambiguous text) to ensure robustness. 3. Troubleshooting & Tips (for Your Risk Taxonomy Use Case) Ensure the model prompt or API returns exact enum strings that match OpenPages enumerated values. The JSON must be clean, valid JSON (no extra text) so JSONata evaluation succeeds. If enum mismatches still occur, build a mapping / post\u2011processor between model output and OpenPages options. Use the minimum confidence threshold to suppress low-confidence results. Iteratively refine your prompt / model training to reduce misclassifications or \u201cno insight found\u201d cases. Use Debug Info display to view raw JSON and help in refining JSONata expressions or prompt logic.","title":"Making the AI feature available in OpenPages"},{"location":"chapter2/3_view_customisation/#lab-13-making-the-ai-feature-available-in-openpages","text":"","title":"Lab 1.3: Making the AI feature available in OpenPages"},{"location":"chapter2/3_view_customisation/#1-add-the-model-to-a-view","text":"The AI model now must be integrated into the view of where we want to interact with it. We want this model on the Risk object so we must navigate to the relevant view. Go to any risk and then turn on debug info via the Administration Menu. The view will then appear beneath the risk heading. Navigate to the view to customize it by clicking on the view name. In the view designer for your object (e.g. Risk view), find the option to add the View AI insight button and drag it into the area on the view in which you want to be able to interact with it. For this use-case, we will add it to the Risk Categorisation area. Add the relevant details to the button parameters to connect your model Save or Publish the view so the model is active in that view.","title":"1. Add the Model to a View"},{"location":"chapter2/3_view_customisation/#2-test-the-model-in-openpages","text":"Navigate to a Risk record in the view where the model is active. Fill in the description (or whatever text triggers the model). A lightbulb / insight icon should appear indicating the model can run (or automatically run). Click on it and observe the side panel with model output suggestions (for Level\u202f1 and Level\u202f2). Validate whether the classifications match expectations. Test edge cases (no clear classification, ambiguous text) to ensure robustness.","title":"2. Test the Model in OpenPages"},{"location":"chapter2/3_view_customisation/#3-troubleshooting-tips-for-your-risk-taxonomy-use-case","text":"Ensure the model prompt or API returns exact enum strings that match OpenPages enumerated values. The JSON must be clean, valid JSON (no extra text) so JSONata evaluation succeeds. If enum mismatches still occur, build a mapping / post\u2011processor between model output and OpenPages options. Use the minimum confidence threshold to suppress low-confidence results. Iteratively refine your prompt / model training to reduce misclassifications or \u201cno insight found\u201d cases. Use Debug Info display to view raw JSON and help in refining JSONata expressions or prompt logic.","title":"3. Troubleshooting &amp; Tips (for Your Risk Taxonomy Use Case)"},{"location":"chapter3/0_index/","text":"Lab 2: Conducting AI Analysis at Scale This lab walks through how to configure and use the Custom Machine Learning Models feature in IBM OpenPages 9.x to conduct 5W analysis of control descriptions and how to do this in an automated workflow. You will: Set up an OpenPages object and view for AI analysis Conduct complex AI analysis and set fields Develop an automated workflow to conduct the AI analysis at scale Prerequisites & Notes - You must have Custom Machine Learning Models permission in OpenPages, otherwise the menu is not visible. - You must have watsonx.ai","title":"Overview"},{"location":"chapter3/0_index/#lab-2-conducting-ai-analysis-at-scale","text":"This lab walks through how to configure and use the Custom Machine Learning Models feature in IBM OpenPages 9.x to conduct 5W analysis of control descriptions and how to do this in an automated workflow. You will: Set up an OpenPages object and view for AI analysis Conduct complex AI analysis and set fields Develop an automated workflow to conduct the AI analysis at scale Prerequisites & Notes - You must have Custom Machine Learning Models permission in OpenPages, otherwise the menu is not visible. - You must have watsonx.ai","title":"Lab 2: Conducting AI Analysis at Scale"},{"location":"chapter3/1_modify_op_object/","text":"Lab 2.1: Modifying an Object in OpenPages In order to display the AI results, we need to modify the relevant OpenPages object, Control , to add fields pertaining to the results we want to see. 1. Adding Object Fields to Relevant Object Type From the Administration menu, go to Solution Configuration \u2192 Object Find Control in the search table. Expand Fields and look for the Control AI field group. This is where we will add our 5W AI analysis output - the control quality rating. Via the Administration menu, click on Enable System Admin Mode . This creates a database lock so that object fields can be modified. Back in the Control object configuration, Click on New Field + . Add a meaningful name, label and description. The data type is and The data type is Enumnerated String with the values matching to the taxonomy that should be output by the AI model. Save, and disable system admin mode after the field group has been created. 2. Adding the New Object Fields to the Control View As in Lab 1.3, navigate to the view customiser for a Control . Add in the new field created for the 5W Control Rating into the view Publish the view.","title":"Modifying an Object in OpenPages"},{"location":"chapter3/1_modify_op_object/#lab-21-modifying-an-object-in-openpages","text":"In order to display the AI results, we need to modify the relevant OpenPages object, Control , to add fields pertaining to the results we want to see.","title":"Lab 2.1: Modifying an Object in OpenPages"},{"location":"chapter3/1_modify_op_object/#1-adding-object-fields-to-relevant-object-type","text":"From the Administration menu, go to Solution Configuration \u2192 Object Find Control in the search table. Expand Fields and look for the Control AI field group. This is where we will add our 5W AI analysis output - the control quality rating. Via the Administration menu, click on Enable System Admin Mode . This creates a database lock so that object fields can be modified. Back in the Control object configuration, Click on New Field + . Add a meaningful name, label and description. The data type is and The data type is Enumnerated String with the values matching to the taxonomy that should be output by the AI model. Save, and disable system admin mode after the field group has been created.","title":"1. Adding Object Fields to Relevant Object Type"},{"location":"chapter3/1_modify_op_object/#2-adding-the-new-object-fields-to-the-control-view","text":"As in Lab 1.3, navigate to the view customiser for a Control . Add in the new field created for the 5W Control Rating into the view Publish the view.","title":"2. Adding the New Object Fields to the Control View"},{"location":"chapter3/2_set_up_and_integrate_ai/","text":"Lab 2.2: Set-up and Integrate AI Model 1. Create and Deploy the Prompt Template in watsonx.ai As per Lab 1.1, create an AI deployment in watsonx.ai for 5W analysis. Use the Control Description as input, and output each of the 5 Ws as well as the Control Rating. Ensure that the Control Rating output aligns with the taxonomy created in Lab 2.1. Here is something to get you started: [INSTRUCTION] > Define the purpose of the AI and it's task < Control Description Format: > Define the input and the definition of each 5W it should ideally contain < Output you need to give within a single json object: 1. > Provide the instruction to extract the 5Ws < 2. > Provide the instruction to generate the Control Quality < 4. > Provide the instruction to generate the explanation of the Control Quality < Generate only a json object, no post script tagging such as [END OF INSTRUCTION]. [FEW-SHOT EXAMPLES] Example 1: Control Description: \"All automated and manual alerts must be assessed in a timely manner in line with the Investigations Standard Operating Procedure (SOP) by investigators and adhere to internal tolerances (WHY). The requirements are outlined in the Institutional Investigations SOP and the Investigation Timing, Tolerances & Appetite document. The Investigations team Lead (WHO) monitors the timeliness of alert assessment at least twice weekly (WHEN) via the Transaction Monitoring and Investigations Dashboard. Metrics (WHAT) are discussed at the monthly Finance Oversight Forum prior to being presented at the Global Working Group Forum. Exceptions are escalated to Head of Finance. Email evidence of escalations and metrics reported to the forums are saved in the Finance SharePoint (WHERE).\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 2: Control Description: \"Multiple levels of review and challenge of the stress testing assumptions and results, from R&CA team members to Division Head to CEO of the Group and the Bank.\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 3: Control Description: \"Why: The control objective is to ensure the adequacy of professional indemnity insurance arrangements for Customer Finance.\\nWhat: On an annual basis, Custody and Product Management review the adequacy of the compensation and insurance arrangements for Customer Finance. In assessing the adequacy of the PI insurance cover, the following information is reviewed: \\n\u2022\\tCustomer Finance\u2019s business activities and financial position \\n\u2022\\tInformation about the PI insurance cover against the requirements under ASIC Regulatory Guide RG126\\nWho: The review is coordinated by The Office of the Trustee with the input from Product Management. \\n\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 4: Control Description: \"[WHO] Prudential Risk CARM, \\n[WHAT] as data consumers, provides performs appropriate checks and reviews of input data, including through variance analysis and four-eyes checks (multiple reviews within Prudential Risk CARM) as outlined in the calculation, Monitoring and Reporting procedures \\n[WHEN] Every quarter, both before (input data check) and after (variance analysis, four-eyes check) generating dashboard, \\n[WHY] To verify the input data and how it is processed by the dashboard, and identify data issues which may require rectification \\n[WHERE] Evidence of the above review and variance analysis is saved in the SharePoint.\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 5: Control Description: \"[WHO] Credit Group [WHAT] notify senior management and escalate [WHEN] which have exceeded APS221 prudential limit thresholds of 25%. [WHY] This is to support regulatory reporting obligations and to provide transparency over management and mitigation of material large exposures.[WHERE] Evidence of large exposure escalations are recorded in an appropriate register.\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } [INPUT] Control Description: {control_description} Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): 2. Integrating Deployed AI Model to OpenPages Once the AI model is deployed in watsonx.ai, it can be integrated into OpenPages. As per Lab 1.2, configure a Custom Machine Learning Model and set up the Model access and Inputs . For Outputs , add outputs for headers for each of the 5Ws (for formatting), as well as the actual output text with the JSONata string that translates the AI model output. Ensure that the Control Rating is set to the target field created in lab 2.1. Add a suitable dscription and customise the style to your choosing in Guidance . Save the model. 3. Add the Model to Control View Navigate to the control object view as per Lab 2.1 to add the AI model we deployed. Rather than add a new AI button, navigate to the Description field and add the 5W model to AI model configuration . Click Done and publish the view. 4. Test the Model in OpenPages Find an example control, and run the 5W AI model that appears near the control description. The rating output will populate the 5W Control Rating field created before.","title":"Set-up and Integrate AI Model"},{"location":"chapter3/2_set_up_and_integrate_ai/#lab-22-set-up-and-integrate-ai-model","text":"","title":"Lab 2.2: Set-up and Integrate AI Model"},{"location":"chapter3/2_set_up_and_integrate_ai/#1-create-and-deploy-the-prompt-template-in-watsonxai","text":"As per Lab 1.1, create an AI deployment in watsonx.ai for 5W analysis. Use the Control Description as input, and output each of the 5 Ws as well as the Control Rating. Ensure that the Control Rating output aligns with the taxonomy created in Lab 2.1. Here is something to get you started: [INSTRUCTION] > Define the purpose of the AI and it's task < Control Description Format: > Define the input and the definition of each 5W it should ideally contain < Output you need to give within a single json object: 1. > Provide the instruction to extract the 5Ws < 2. > Provide the instruction to generate the Control Quality < 4. > Provide the instruction to generate the explanation of the Control Quality < Generate only a json object, no post script tagging such as [END OF INSTRUCTION]. [FEW-SHOT EXAMPLES] Example 1: Control Description: \"All automated and manual alerts must be assessed in a timely manner in line with the Investigations Standard Operating Procedure (SOP) by investigators and adhere to internal tolerances (WHY). The requirements are outlined in the Institutional Investigations SOP and the Investigation Timing, Tolerances & Appetite document. The Investigations team Lead (WHO) monitors the timeliness of alert assessment at least twice weekly (WHEN) via the Transaction Monitoring and Investigations Dashboard. Metrics (WHAT) are discussed at the monthly Finance Oversight Forum prior to being presented at the Global Working Group Forum. Exceptions are escalated to Head of Finance. Email evidence of escalations and metrics reported to the forums are saved in the Finance SharePoint (WHERE).\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 2: Control Description: \"Multiple levels of review and challenge of the stress testing assumptions and results, from R&CA team members to Division Head to CEO of the Group and the Bank.\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 3: Control Description: \"Why: The control objective is to ensure the adequacy of professional indemnity insurance arrangements for Customer Finance.\\nWhat: On an annual basis, Custody and Product Management review the adequacy of the compensation and insurance arrangements for Customer Finance. In assessing the adequacy of the PI insurance cover, the following information is reviewed: \\n\u2022\\tCustomer Finance\u2019s business activities and financial position \\n\u2022\\tInformation about the PI insurance cover against the requirements under ASIC Regulatory Guide RG126\\nWho: The review is coordinated by The Office of the Trustee with the input from Product Management. \\n\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 4: Control Description: \"[WHO] Prudential Risk CARM, \\n[WHAT] as data consumers, provides performs appropriate checks and reviews of input data, including through variance analysis and four-eyes checks (multiple reviews within Prudential Risk CARM) as outlined in the calculation, Monitoring and Reporting procedures \\n[WHEN] Every quarter, both before (input data check) and after (variance analysis, four-eyes check) generating dashboard, \\n[WHY] To verify the input data and how it is processed by the dashboard, and identify data issues which may require rectification \\n[WHERE] Evidence of the above review and variance analysis is saved in the SharePoint.\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } Example 5: Control Description: \"[WHO] Credit Group [WHAT] notify senior management and escalate [WHEN] which have exceeded APS221 prudential limit thresholds of 25%. [WHY] This is to support regulatory reporting obligations and to provide transparency over management and mitigation of material large exposures.[WHERE] Evidence of large exposure escalations are recorded in an appropriate register.\" Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output): { \"Who\": > The who <, \"What\": > The what <, \"When\": > The when <, \"Where\": > The where <, \"Why\": > The why <, \"Control Quality\": > The control quality <, \"Control Quality Explain\": > An explanation of why the control quality is the way it is< } [INPUT] Control Description: {control_description} Question: What is the JSON Output with no markup and no backticks for 5W description analysis? Response (JSON Output):","title":"1. Create and Deploy the Prompt Template in watsonx.ai"},{"location":"chapter3/2_set_up_and_integrate_ai/#2-integrating-deployed-ai-model-to-openpages","text":"Once the AI model is deployed in watsonx.ai, it can be integrated into OpenPages. As per Lab 1.2, configure a Custom Machine Learning Model and set up the Model access and Inputs . For Outputs , add outputs for headers for each of the 5Ws (for formatting), as well as the actual output text with the JSONata string that translates the AI model output. Ensure that the Control Rating is set to the target field created in lab 2.1. Add a suitable dscription and customise the style to your choosing in Guidance . Save the model.","title":"2. Integrating Deployed AI Model to OpenPages"},{"location":"chapter3/2_set_up_and_integrate_ai/#3-add-the-model-to-control-view","text":"Navigate to the control object view as per Lab 2.1 to add the AI model we deployed. Rather than add a new AI button, navigate to the Description field and add the 5W model to AI model configuration . Click Done and publish the view.","title":"3. Add the Model to Control View"},{"location":"chapter3/2_set_up_and_integrate_ai/#4-test-the-model-in-openpages","text":"Find an example control, and run the 5W AI model that appears near the control description. The rating output will populate the 5W Control Rating field created before.","title":"4. Test the Model in OpenPages"},{"location":"chapter3/3_bulk_analysis/","text":"Lab 2.3: Execute AI in Bulk So far, we have been executing AI through user interactions - let's look at how we can apply AI at scale. 1. Create workflow So that we don't execute the AI against every single control, first identify candidate records. We can do this by adding a dummy field called '5W Candidate', adding it to the Control view and then setting this as a valid value for a few controls. Later we will add it as a condition for the workflow. From the Administration menu, go to Solution Configuration \u2192 Workflows Create a new workflow. Provide the following parameters: Name: Add a suitable name Object type: Control Choose how the workflow starts: User action or scheduler Allow user to start workflow through the task view: Yes Enabled: Yes Automated: No Add only a start and end block. Add an action connecting the start to the end block. Provide the following: Name: Add a suitable name Label: Add a suitable label Run In Background: False Auto-Advance Stage: True Provide no conditions. Click New Operation + under Validations and Operations to add the AI model. For the new operation, provide the following: Operation: Run an AI Model Name: Add a suitable name When: Keep empty Advanced Logic: False Execute As System: False Target Objects: Self Model: Select your deployed AI model Clicking on the empty area in the canvas will display the Workflow Properties . Scroll down to Applicability and click New Condition + . In the new condition, ensure that the 5W Candidate field created earlier is equal to a specific value that you set candidate records as. Publish the workflow. 2. View Results at Scale Modify the Control Grid View to see the 5W results at a high level. Via the hamburger menu, navigate to Assessments > Controls . With Debug Info displayed, naviagte to the View for the Control Grid. [screenshot with cursor hovering over the control grid view name] Add the 5W Control Rating field to the grid and publish the view. 3. Test the Bulk AI Execution Go back to the workflows page. Select the workflow created for the 5W Bulk Control Analysis and start the workflow. We can check the progress of the workflow in Administration menu, go to Other \u2192 Background Processes We can see the output by going to our Control grid view and using the 5W Candidate field as a filter","title":"Execute AI in Bulk"},{"location":"chapter3/3_bulk_analysis/#lab-23-execute-ai-in-bulk","text":"So far, we have been executing AI through user interactions - let's look at how we can apply AI at scale.","title":"Lab 2.3: Execute AI in Bulk"},{"location":"chapter3/3_bulk_analysis/#1-create-workflow","text":"So that we don't execute the AI against every single control, first identify candidate records. We can do this by adding a dummy field called '5W Candidate', adding it to the Control view and then setting this as a valid value for a few controls. Later we will add it as a condition for the workflow. From the Administration menu, go to Solution Configuration \u2192 Workflows Create a new workflow. Provide the following parameters: Name: Add a suitable name Object type: Control Choose how the workflow starts: User action or scheduler Allow user to start workflow through the task view: Yes Enabled: Yes Automated: No Add only a start and end block. Add an action connecting the start to the end block. Provide the following: Name: Add a suitable name Label: Add a suitable label Run In Background: False Auto-Advance Stage: True Provide no conditions. Click New Operation + under Validations and Operations to add the AI model. For the new operation, provide the following: Operation: Run an AI Model Name: Add a suitable name When: Keep empty Advanced Logic: False Execute As System: False Target Objects: Self Model: Select your deployed AI model Clicking on the empty area in the canvas will display the Workflow Properties . Scroll down to Applicability and click New Condition + . In the new condition, ensure that the 5W Candidate field created earlier is equal to a specific value that you set candidate records as. Publish the workflow.","title":"1. Create workflow"},{"location":"chapter3/3_bulk_analysis/#2-view-results-at-scale","text":"Modify the Control Grid View to see the 5W results at a high level. Via the hamburger menu, navigate to Assessments > Controls . With Debug Info displayed, naviagte to the View for the Control Grid. [screenshot with cursor hovering over the control grid view name] Add the 5W Control Rating field to the grid and publish the view.","title":"2. View Results at Scale"},{"location":"chapter3/3_bulk_analysis/#3-test-the-bulk-ai-execution","text":"Go back to the workflows page. Select the workflow created for the 5W Bulk Control Analysis and start the workflow. We can check the progress of the workflow in Administration menu, go to Other \u2192 Background Processes We can see the output by going to our Control grid view and using the 5W Candidate field as a filter","title":"3. Test the Bulk AI Execution"},{"location":"chapter4/0_index/","text":"Lab 3: Creating Custom Input Sources for AI Analysis This lab walks through how to configure and use the Custom Machine Learning Models feature in IBM OpenPages 9.x to create custom views for more complex AI analysis that draws on data from multiple objects. You will: Set up a custom input view in OpenPages for AI analysis Validate the input data using logs Develop and deploy the prompt to conduct analysis Integrate the deployed ML model into a view that a user can trigger the AI analysis with Prerequisites & Notes - You must have Custom Machine Learning Models permission in OpenPages, otherwise the menu is not visible. - You must have watsonx.ai For Lab 3, please navigate to Use-case 11 here: https://community.ibm.com/community/user/discussion/watsonxai-prompt-for-openpages-examples","title":"Overview"},{"location":"chapter4/0_index/#lab-3-creating-custom-input-sources-for-ai-analysis","text":"This lab walks through how to configure and use the Custom Machine Learning Models feature in IBM OpenPages 9.x to create custom views for more complex AI analysis that draws on data from multiple objects. You will: Set up a custom input view in OpenPages for AI analysis Validate the input data using logs Develop and deploy the prompt to conduct analysis Integrate the deployed ML model into a view that a user can trigger the AI analysis with Prerequisites & Notes - You must have Custom Machine Learning Models permission in OpenPages, otherwise the menu is not visible. - You must have watsonx.ai For Lab 3, please navigate to Use-case 11 here: https://community.ibm.com/community/user/discussion/watsonxai-prompt-for-openpages-examples","title":"Lab 3: Creating Custom Input Sources for AI Analysis"},{"location":"chapter4/1_configure_view_input/","text":"Lab 3.1: Configuring a Custom View as Input for ML Models Consider a situation where you want to conduct AI analysis but the inputs don't all belong to a single object. The solution is to create a custom view that contains all the relevant bits of information required to complete the analysis. An example of this would be generating an executive summary for a risk assessment. In this case, we would analyze: - Processes - Risks for each of the processes - Controls mitigating the above risks - Issues identified for each controls Each of these are different objects but would have relationships. 1. Creating the View From the Administration menu, go to Solution Configuration \u2192 Views Find an appropriate view as a starting point. For this Risk Assessment Executive Summary use-case, we will use the Risk Assessment view (Demo-Task-RiskAssessment-4-ORM) because it will logically contain most of the input data we need. Copy the view add the following parameters: Name: Add a suitable name Label: Add a suitable lavel Type: Task Enabled: \u2705 Go to your new view and add in the relevant object inputs. These are best brought in as grids so that multiple fields for each object can be input into the ML model. Where the relationship type is not direct (either parent/child), select all relevant relationship paths. An example of this is shown below, where Processes are a directly related object but Proces Risks ( Descendants relationship type) are not therefore the relationship types must be selected. Do the same for: - Direct Risks; the Children relationship type for the Risk object (selecting Name, Description, Inherent Risk Rating, Residual Risk Rating, Owner, Status) - Controls (selecting Name, Description, Design Effectiveness, Operating Effeftiveness, Control Owner, Status) - Issues (selecting Name, Description, Priority, Lifecycle Due Date, Issue Owner, Issue Status) Publish the view.","title":"Configuring a Custom View as Input for ML Models"},{"location":"chapter4/1_configure_view_input/#lab-31-configuring-a-custom-view-as-input-for-ml-models","text":"Consider a situation where you want to conduct AI analysis but the inputs don't all belong to a single object. The solution is to create a custom view that contains all the relevant bits of information required to complete the analysis. An example of this would be generating an executive summary for a risk assessment. In this case, we would analyze: - Processes - Risks for each of the processes - Controls mitigating the above risks - Issues identified for each controls Each of these are different objects but would have relationships.","title":"Lab 3.1: Configuring a Custom View as Input for ML Models"},{"location":"chapter4/1_configure_view_input/#1-creating-the-view","text":"From the Administration menu, go to Solution Configuration \u2192 Views Find an appropriate view as a starting point. For this Risk Assessment Executive Summary use-case, we will use the Risk Assessment view (Demo-Task-RiskAssessment-4-ORM) because it will logically contain most of the input data we need. Copy the view add the following parameters: Name: Add a suitable name Label: Add a suitable lavel Type: Task Enabled: \u2705 Go to your new view and add in the relevant object inputs. These are best brought in as grids so that multiple fields for each object can be input into the ML model. Where the relationship type is not direct (either parent/child), select all relevant relationship paths. An example of this is shown below, where Processes are a directly related object but Proces Risks ( Descendants relationship type) are not therefore the relationship types must be selected. Do the same for: - Direct Risks; the Children relationship type for the Risk object (selecting Name, Description, Inherent Risk Rating, Residual Risk Rating, Owner, Status) - Controls (selecting Name, Description, Design Effectiveness, Operating Effeftiveness, Control Owner, Status) - Issues (selecting Name, Description, Priority, Lifecycle Due Date, Issue Owner, Issue Status) Publish the view.","title":"1. Creating the View"},{"location":"chapter4/2_validate_view_input/","text":"Lab 3.2: Set-up and Integrate AI Model With a view input created, we need to get the format the data will be sent to the AI model in so we can test our prompt with it, and confirm that it actually contains all the information we need to perform our AI analysis. 1. Set-up OpenPages Logging so that Machine Learning Information is Recorded We will capture the data format by accessing the logs inside OpenPages, and so this must be configured correctly first. From the Administration \u2699\ufe0f menu, go to System Configuration \u2192 Settings . By default, OpenPages obfuscates the request and response payloads for security. We must disable this - In settings, navigate to: /OpenPages/Applications/Common/Administration/Integrations/Logs/Obfuscation Disabled . Ensure the value is set to true . From the Administration \u2699\ufe0f menu, go to Other \u2192 Logs . In System tracing options ensure only Machine Learning is checked. Click Save. 2. Deploy a Dummy AI Model We need extract the exact payload of our view that OpenPages sends to watsonx.ai. To do this, we need to configure an AI insight trigger that calls our input view. We can achieve this by deploying a dummy AI model that calls our view input, into another view that a user will interact with the AI in. The payload will be sent to the dummy AI model. In watsonx.ai, deploy a prompt template with the following: This is a dummy AI model. For the following input: {objectJson} Generate the word \"Yes\". 3. Integrating Deployed Dummy AI Model to OpenPages From the Administration menu, go to Integrations \u2192 Custom Machine Learning Models . Click New Model to begin configuring a new integration. On the \u201cNew Model\u201d screen: Enter Name and Label (e.g. view_input_test ) Select the AI Service Type (e.g. Watson Machine Learning on IBM Cloud) Enter Access Parameters such as: Watson service type: Watson Machine Learning on Cloud Authentication URL: https://iam.cloud.ibm.com/identity/token API Key: Retrieve from IBM Cloud Base Deployment URL: https://us-south.ml.cloud.ibm.com/ml/v4 Deployment ID: Retrieve from dummy AI model deployment space on watsonx.ai Space ID: Retrieve from model/prompt template deployment on watsonx.ai API version: 2021-05-01 Click Test Connection to verify connectivity Set the Input type as view definition and select the appropriate object type (Risk Assessment). For Outputs , select Insight type as display only with dummy text for the output label and JSONata string. Add a suitable description and customise the style to your choosing in Guidance . Save the model. 4. Add the Dummy Model to a View Navigate to the relevant object view (Risk Assessment) to add the AI model we deployed. Add a new View AI Insights button, adding a suitable label and the dummy AI model for Select AI model integration . Select the view created in Lab 3.1 for Select a view to send to the model . Publish the view 5. Test the Dummy Model in OpenPages Find an example Risk Assessment, and run the Dummy Model in the area you placed in the previous step. 6. Access the OpenPages Logs to Find the View Input Payload Now that the payload has been sent to watsonx.ai, we can track down the exact input by accessing the OpenPages logs. From the Administration \u2699\ufe0f menu, go to Other \u2192 Logs . Launch the Log Collector. Only the Log Files option needs to be selected. Wait for the logging to complete. This could take a few minutes depending on what you have selected for System tracing options. That's why it is recommended only to select machine learning. Once the logging is complete, download the file. Unzip the archive and navigate to LogCollector_{date}_OPNodeServer1/OpenPages/aurora/logs/debug/OpenPagesNodeServerServer1-machinelearning.log This file contains detailed entries for each AI interaction, including the constructed prompt, the JSON payload, and the LLM\u2019s response.Look for the line that contains a request corresponding to the time you clicked the AI button. The payload sent to your model is then the value against the objectJson key. Here is an example of the payload: { \"guidance\": { \"\": \"\", \"incompletedRequiredItems\": [], \"incompleteOptionalItems\": [], \"completedItems\": [ \"Description\", \"Name\" ] }, \"objectTypeLabel\": \"Risk Assessment\", \"Related Information\": { \"Tab Group-0000\": { \"Process Risks\": { \"relationshipType\": \"descendants\", \"objectTypeName\": \"SOXRisk\", \"relatedObjects\": [] }, \"Issue Summary\": { \"relationshipType\": \"descendants\", \"objectTypeName\": \"SOXIssue\", \"relatedObjects\": [] }, \"Direct Risks\": { \"relationshipType\": \"children\", \"objectTypeName\": \"SOXRisk\", \"relatedObjects\": [ { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Risk Assessment and Treatment Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111040, \"parentId\": 111037, \"Name\": \"RSK-SA-001\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Security Policy Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111042, \"parentId\": 111037, \"Name\": \"RSK-SA-002\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Organization Security Risk\", \"Residual Risk Rating\": \"High\", \"id\": 111044, \"parentId\": 111037, \"Name\": \"RSK-SA-003\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Asset and Information Management Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111046, \"parentId\": 111037, \"Name\": \"RSK-SA-004\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Human Resource Security Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111048, \"parentId\": 111037, \"Name\": \"RSK-SA-005\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Physical and Environmental Security Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111050, \"parentId\": 111037, \"Name\": \"RSK-SA-006\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Operations Management Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111052, \"parentId\": 111037, \"Name\": \"RSK-SA-007\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Access Control Risk\", \"Residual Risk Rating\": \"High\", \"id\": 111054, \"parentId\": 111037, \"Name\": \"RSK-SA-008\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Application Security Risk\", \"Residual Risk Rating\": \"Very High\", \"id\": 111056, \"parentId\": 111037, \"Name\": \"RSK-SA-009\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Incident Event and Communications Management Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111058, \"parentId\": 111037, \"Name\": \"RSK-SA-010\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Business Resiliency Risk\", \"Residual Risk Rating\": \"Very High\", \"id\": 111060, \"parentId\": 111037, \"Name\": \"RSK-SA-011\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Compliance Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111062, \"parentId\": 111037, \"Name\": \"RSK-SA-012\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"End User Device Security Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111064, \"parentId\": 111037, \"Name\": \"RSK-SA-013\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Network Security Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111066, \"parentId\": 111037, \"Name\": \"RSK-SA-014\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Privacy Risk\", \"Residual Risk Rating\": \"High\", \"id\": 111068, \"parentId\": 111037, \"Name\": \"RSK-SA-015\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Threat Management Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111070, \"parentId\": 111037, \"Name\": \"RSK-SA-016\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Server Security Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111072, \"parentId\": 111037, \"Name\": \"RSK-SA-017\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Cloud Hosting Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111074, \"parentId\": 111037, \"Name\": \"RSK-SA-018\" } ] }, \"Controls\": { \"relationshipType\": \"descendants\", \"objectTypeName\": \"SOXControl\", \"relatedObjects\": [ { \"Status\": \"Awaiting Assessment\", \"Description\": \"A comprehensive Risk Governance Plan is in Place including Policies, Procedures, and Internal Controls\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Not Determined\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111077, \"parentId\": 111040, \"Name\": \"CTRL-SA-001\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"An Information Security Policy Program has been established and implemented based on industry accepted standards and practices\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111079, \"parentId\": 111042, \"Name\": \"CTRL-SA-002\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Local and Site-specific security risk processes are implemented to adequately manage organizational security risk\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Ineffective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111081, \"parentId\": 111044, \"Name\": \"CTRL-SA-003\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"The Asset Inventory or CMDB is updated periodically and Asset Information is adquate and complete\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Ineffective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111083, \"parentId\": 111046, \"Name\": \"CTRL-SA-004\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"A human resource policy is approved by management, communicated to all constituents, and includes comprehensive background checks.\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111085, \"parentId\": 111048, \"Name\": \"CTRL-SA-005\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"A Physical Security program including physical access and environmental controls is implemented and approved by Management.\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111087, \"parentId\": 111050, \"Name\": \"CTRL-SA-006\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Operating procedures are documented, maintained, and made available to all users\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111089, \"parentId\": 111052, \"Name\": \"CTRL-SA-007\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Access Control Policy is implemented and preventative controls are in place to prevent access to client data.\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111091, \"parentId\": 111054, \"Name\": \"CTRL-SA-008\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Applicatoins that transmit, process, or store scoped data have been reviewed by security experts\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111093, \"parentId\": 111056, \"Name\": \"CTRL-SA-009\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Incidents are properly documented, managed, and addressed in accordance with SLA's\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111095, \"parentId\": 111058, \"Name\": \"CTRL-SA-010\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"There is an established business resiliency program that has been approved by management, communicated to appropriate constituents, and an owner to maintain and review the program\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111097, \"parentId\": 111060, \"Name\": \"CTRL-SA-011\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"There are policies and procedures to ensure compliance with applicable legislative, regulatory and contractual requirements including intellectual property rights on business processes or information technology software products\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111099, \"parentId\": 111062, \"Name\": \"CTRL-SA-012\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"End user device security configuration standards are reviewed and/or updated at least annually to account for any changes in environment, available security features and/or best practices\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111101, \"parentId\": 111064, \"Name\": \"CTRL-SA-013\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Reviews are performed to validate compliance with documented standards at least annually\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111103, \"parentId\": 111066, \"Name\": \"CTRL-SA-014\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Client Data is scoped collected, transmitted, processed, or stored that can be classified as non-public information (NPI), personally identifiable information (PII), or personally identifiable financial information\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111105, \"parentId\": 111068, \"Name\": \"CTRL-SA-015\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"The anti-malware policy or program includes defined operating systems that require antivirus\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111107, \"parentId\": 111070, \"Name\": \"CTRL-SA-016\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Server security configuration reviews are performed regularly to validate compliance with documented standards\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111109, \"parentId\": 111072, \"Name\": \"CTRL-SA-017\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"An Internet-accessible self-service portal is available that allows clients to configure security settings and view access logs, security events and alerts\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111111, \"parentId\": 111074, \"Name\": \"CTRL-SA-018\" } ] }, \"Attachments\": { \"relationshipType\": \"children\", \"objectTypeName\": \"SOXDocument\", \"relatedObjects\": [] } } }, \"name\": \"1-TPRM-VRA-SCA-BigTech\", \"objectTypeName\": \"RiskAssessment\", \"header\": { \"Status\": \"Awaiting Assessment\", \"Type\": \"Qualitative\", \"Number of Issues\": 0 }, \"RCSA Dates\": { \"group-dates\": { \"Next Assessment Date\": \"\", \"Start Date\": \"6/18/2022\", \"End Date\": \"7/16/2022\", \"Frequency\": \"Quarterly\" } }, \"Overview\": { \"Guidance\": \"\", \"Description\": \"Vendor Standardized Risk and Control Assessment\", \"group-owners\": { \"Status\": \"Awaiting Assessment\", \"Risk Assessment Type\": \"Third Party\", \"Type\": \"Qualitative\", \"Domain\": \"Compliance\", \"Assessor\": \"Vicky Manfred [vendormanager]\", \"Reviewer\": \"Vicky Manfred [vendormanager]\" }, \"Name\": \"1-TPRM-VRA-SCA-BigTech\" }, \"id\": \"111037\", \"Processes In Scope\": { \"Scoping\": \"Scope the Assessment by associating to processes.\\\\nAll child risks of a process will be then deemdeed to be in scope and shown in the grids below\", \"Tab Group-0001\": { \"Processes\": { \"relationshipType\": \"children\", \"objectTypeName\": \"SOXProcess\", \"relatedObjects\": [] } } } }","title":"Validate the View Input"},{"location":"chapter4/2_validate_view_input/#lab-32-set-up-and-integrate-ai-model","text":"With a view input created, we need to get the format the data will be sent to the AI model in so we can test our prompt with it, and confirm that it actually contains all the information we need to perform our AI analysis.","title":"Lab 3.2: Set-up and Integrate AI Model"},{"location":"chapter4/2_validate_view_input/#1-set-up-openpages-logging-so-that-machine-learning-information-is-recorded","text":"We will capture the data format by accessing the logs inside OpenPages, and so this must be configured correctly first. From the Administration \u2699\ufe0f menu, go to System Configuration \u2192 Settings . By default, OpenPages obfuscates the request and response payloads for security. We must disable this - In settings, navigate to: /OpenPages/Applications/Common/Administration/Integrations/Logs/Obfuscation Disabled . Ensure the value is set to true . From the Administration \u2699\ufe0f menu, go to Other \u2192 Logs . In System tracing options ensure only Machine Learning is checked. Click Save.","title":"1. Set-up OpenPages Logging so that Machine Learning Information is Recorded"},{"location":"chapter4/2_validate_view_input/#2-deploy-a-dummy-ai-model","text":"We need extract the exact payload of our view that OpenPages sends to watsonx.ai. To do this, we need to configure an AI insight trigger that calls our input view. We can achieve this by deploying a dummy AI model that calls our view input, into another view that a user will interact with the AI in. The payload will be sent to the dummy AI model. In watsonx.ai, deploy a prompt template with the following: This is a dummy AI model. For the following input: {objectJson} Generate the word \"Yes\".","title":"2. Deploy a Dummy AI Model"},{"location":"chapter4/2_validate_view_input/#3-integrating-deployed-dummy-ai-model-to-openpages","text":"From the Administration menu, go to Integrations \u2192 Custom Machine Learning Models . Click New Model to begin configuring a new integration. On the \u201cNew Model\u201d screen: Enter Name and Label (e.g. view_input_test ) Select the AI Service Type (e.g. Watson Machine Learning on IBM Cloud) Enter Access Parameters such as: Watson service type: Watson Machine Learning on Cloud Authentication URL: https://iam.cloud.ibm.com/identity/token API Key: Retrieve from IBM Cloud Base Deployment URL: https://us-south.ml.cloud.ibm.com/ml/v4 Deployment ID: Retrieve from dummy AI model deployment space on watsonx.ai Space ID: Retrieve from model/prompt template deployment on watsonx.ai API version: 2021-05-01 Click Test Connection to verify connectivity Set the Input type as view definition and select the appropriate object type (Risk Assessment). For Outputs , select Insight type as display only with dummy text for the output label and JSONata string. Add a suitable description and customise the style to your choosing in Guidance . Save the model.","title":"3. Integrating Deployed Dummy AI Model to OpenPages"},{"location":"chapter4/2_validate_view_input/#4-add-the-dummy-model-to-a-view","text":"Navigate to the relevant object view (Risk Assessment) to add the AI model we deployed. Add a new View AI Insights button, adding a suitable label and the dummy AI model for Select AI model integration . Select the view created in Lab 3.1 for Select a view to send to the model . Publish the view","title":"4. Add the Dummy Model to a View"},{"location":"chapter4/2_validate_view_input/#5-test-the-dummy-model-in-openpages","text":"Find an example Risk Assessment, and run the Dummy Model in the area you placed in the previous step.","title":"5. Test the Dummy Model in OpenPages"},{"location":"chapter4/2_validate_view_input/#6-access-the-openpages-logs-to-find-the-view-input-payload","text":"Now that the payload has been sent to watsonx.ai, we can track down the exact input by accessing the OpenPages logs. From the Administration \u2699\ufe0f menu, go to Other \u2192 Logs . Launch the Log Collector. Only the Log Files option needs to be selected. Wait for the logging to complete. This could take a few minutes depending on what you have selected for System tracing options. That's why it is recommended only to select machine learning. Once the logging is complete, download the file. Unzip the archive and navigate to LogCollector_{date}_OPNodeServer1/OpenPages/aurora/logs/debug/OpenPagesNodeServerServer1-machinelearning.log This file contains detailed entries for each AI interaction, including the constructed prompt, the JSON payload, and the LLM\u2019s response.Look for the line that contains a request corresponding to the time you clicked the AI button. The payload sent to your model is then the value against the objectJson key. Here is an example of the payload: { \"guidance\": { \"\": \"\", \"incompletedRequiredItems\": [], \"incompleteOptionalItems\": [], \"completedItems\": [ \"Description\", \"Name\" ] }, \"objectTypeLabel\": \"Risk Assessment\", \"Related Information\": { \"Tab Group-0000\": { \"Process Risks\": { \"relationshipType\": \"descendants\", \"objectTypeName\": \"SOXRisk\", \"relatedObjects\": [] }, \"Issue Summary\": { \"relationshipType\": \"descendants\", \"objectTypeName\": \"SOXIssue\", \"relatedObjects\": [] }, \"Direct Risks\": { \"relationshipType\": \"children\", \"objectTypeName\": \"SOXRisk\", \"relatedObjects\": [ { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Risk Assessment and Treatment Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111040, \"parentId\": 111037, \"Name\": \"RSK-SA-001\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Security Policy Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111042, \"parentId\": 111037, \"Name\": \"RSK-SA-002\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Organization Security Risk\", \"Residual Risk Rating\": \"High\", \"id\": 111044, \"parentId\": 111037, \"Name\": \"RSK-SA-003\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Asset and Information Management Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111046, \"parentId\": 111037, \"Name\": \"RSK-SA-004\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Human Resource Security Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111048, \"parentId\": 111037, \"Name\": \"RSK-SA-005\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Physical and Environmental Security Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111050, \"parentId\": 111037, \"Name\": \"RSK-SA-006\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Operations Management Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111052, \"parentId\": 111037, \"Name\": \"RSK-SA-007\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Access Control Risk\", \"Residual Risk Rating\": \"High\", \"id\": 111054, \"parentId\": 111037, \"Name\": \"RSK-SA-008\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Application Security Risk\", \"Residual Risk Rating\": \"Very High\", \"id\": 111056, \"parentId\": 111037, \"Name\": \"RSK-SA-009\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Incident Event and Communications Management Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111058, \"parentId\": 111037, \"Name\": \"RSK-SA-010\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Business Resiliency Risk\", \"Residual Risk Rating\": \"Very High\", \"id\": 111060, \"parentId\": 111037, \"Name\": \"RSK-SA-011\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Compliance Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111062, \"parentId\": 111037, \"Name\": \"RSK-SA-012\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"End User Device Security Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111064, \"parentId\": 111037, \"Name\": \"RSK-SA-013\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Network Security Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111066, \"parentId\": 111037, \"Name\": \"RSK-SA-014\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"High\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Privacy Risk\", \"Residual Risk Rating\": \"High\", \"id\": 111068, \"parentId\": 111037, \"Name\": \"RSK-SA-015\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Threat Management Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111070, \"parentId\": 111037, \"Name\": \"RSK-SA-016\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Medium\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Server Security Risk\", \"Residual Risk Rating\": \"Medium\", \"id\": 111072, \"parentId\": 111037, \"Name\": \"RSK-SA-017\" }, { \"Status\": \"Awaiting Assessment\", \"Inherent Risk Rating\": \"Low\", \"Owner\": \"OpenPagesAdministrator\", \"Description\": \"Cloud Hosting Risk\", \"Residual Risk Rating\": \"Low\", \"id\": 111074, \"parentId\": 111037, \"Name\": \"RSK-SA-018\" } ] }, \"Controls\": { \"relationshipType\": \"descendants\", \"objectTypeName\": \"SOXControl\", \"relatedObjects\": [ { \"Status\": \"Awaiting Assessment\", \"Description\": \"A comprehensive Risk Governance Plan is in Place including Policies, Procedures, and Internal Controls\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Not Determined\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111077, \"parentId\": 111040, \"Name\": \"CTRL-SA-001\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"An Information Security Policy Program has been established and implemented based on industry accepted standards and practices\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111079, \"parentId\": 111042, \"Name\": \"CTRL-SA-002\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Local and Site-specific security risk processes are implemented to adequately manage organizational security risk\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Ineffective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111081, \"parentId\": 111044, \"Name\": \"CTRL-SA-003\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"The Asset Inventory or CMDB is updated periodically and Asset Information is adquate and complete\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Ineffective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111083, \"parentId\": 111046, \"Name\": \"CTRL-SA-004\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"A human resource policy is approved by management, communicated to all constituents, and includes comprehensive background checks.\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111085, \"parentId\": 111048, \"Name\": \"CTRL-SA-005\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"A Physical Security program including physical access and environmental controls is implemented and approved by Management.\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111087, \"parentId\": 111050, \"Name\": \"CTRL-SA-006\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Operating procedures are documented, maintained, and made available to all users\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111089, \"parentId\": 111052, \"Name\": \"CTRL-SA-007\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Access Control Policy is implemented and preventative controls are in place to prevent access to client data.\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111091, \"parentId\": 111054, \"Name\": \"CTRL-SA-008\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Applicatoins that transmit, process, or store scoped data have been reviewed by security experts\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111093, \"parentId\": 111056, \"Name\": \"CTRL-SA-009\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Incidents are properly documented, managed, and addressed in accordance with SLA's\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111095, \"parentId\": 111058, \"Name\": \"CTRL-SA-010\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"There is an established business resiliency program that has been approved by management, communicated to appropriate constituents, and an owner to maintain and review the program\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111097, \"parentId\": 111060, \"Name\": \"CTRL-SA-011\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"There are policies and procedures to ensure compliance with applicable legislative, regulatory and contractual requirements including intellectual property rights on business processes or information technology software products\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111099, \"parentId\": 111062, \"Name\": \"CTRL-SA-012\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"End user device security configuration standards are reviewed and/or updated at least annually to account for any changes in environment, available security features and/or best practices\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111101, \"parentId\": 111064, \"Name\": \"CTRL-SA-013\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Reviews are performed to validate compliance with documented standards at least annually\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111103, \"parentId\": 111066, \"Name\": \"CTRL-SA-014\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Client Data is scoped collected, transmitted, processed, or stored that can be classified as non-public information (NPI), personally identifiable information (PII), or personally identifiable financial information\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111105, \"parentId\": 111068, \"Name\": \"CTRL-SA-015\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"The anti-malware policy or program includes defined operating systems that require antivirus\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111107, \"parentId\": 111070, \"Name\": \"CTRL-SA-016\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"Server security configuration reviews are performed regularly to validate compliance with documented standards\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111109, \"parentId\": 111072, \"Name\": \"CTRL-SA-017\" }, { \"Status\": \"Awaiting Assessment\", \"Description\": \"An Internet-accessible self-service portal is available that allows clients to configure security settings and view access logs, security events and alerts\", \"Design Effectiveness\": \"Effective\", \"Operating Effectiveness\": \"Effective\", \"Control Owner\": \"OpenPagesAdministrator\", \"id\": 111111, \"parentId\": 111074, \"Name\": \"CTRL-SA-018\" } ] }, \"Attachments\": { \"relationshipType\": \"children\", \"objectTypeName\": \"SOXDocument\", \"relatedObjects\": [] } } }, \"name\": \"1-TPRM-VRA-SCA-BigTech\", \"objectTypeName\": \"RiskAssessment\", \"header\": { \"Status\": \"Awaiting Assessment\", \"Type\": \"Qualitative\", \"Number of Issues\": 0 }, \"RCSA Dates\": { \"group-dates\": { \"Next Assessment Date\": \"\", \"Start Date\": \"6/18/2022\", \"End Date\": \"7/16/2022\", \"Frequency\": \"Quarterly\" } }, \"Overview\": { \"Guidance\": \"\", \"Description\": \"Vendor Standardized Risk and Control Assessment\", \"group-owners\": { \"Status\": \"Awaiting Assessment\", \"Risk Assessment Type\": \"Third Party\", \"Type\": \"Qualitative\", \"Domain\": \"Compliance\", \"Assessor\": \"Vicky Manfred [vendormanager]\", \"Reviewer\": \"Vicky Manfred [vendormanager]\" }, \"Name\": \"1-TPRM-VRA-SCA-BigTech\" }, \"id\": \"111037\", \"Processes In Scope\": { \"Scoping\": \"Scope the Assessment by associating to processes.\\\\nAll child risks of a process will be then deemdeed to be in scope and shown in the grids below\", \"Tab Group-0001\": { \"Processes\": { \"relationshipType\": \"children\", \"objectTypeName\": \"SOXProcess\", \"relatedObjects\": [] } } } }","title":"6. Access the OpenPages Logs to Find the View Input Payload"},{"location":"chapter4/3_prompt/","text":"Lab 3.3: Develop and Deploy Prompt Now knowing the exact input type, we can create a prompt for our desired output. 1. Set Up and Deploy the prompt in Prompt Lab As per Lab 1.1, develop and deploy the prompt. The only difference is the input data will be the json object we identified in the last step, and the prompt template variable must be objectJson Here is an example prompt: You are a compliance and risk expert writing an executive summary for a third-party qualitative risk assessment. Given the following JSON input (representing a risk assessment in OpenPages), summarize the key information in professional business language. Your summary should: - Begin with a brief description of the purpose of the risk assessment. - Mention the assessment type (e.g., Third Party, Qualitative), assessor, and reviewer. - Highlight the assessment period and frequency. - Summarize how many direct risks were identified, and break them down by their **Inherent** and **Residual Risk Ratings** (e.g., how many were High, Medium, Low, Very High). - Identify any particularly critical risks (e.g., High Inherent AND High Residual). - Include a high-level overview of the control environment: how many controls are mapped, and summarize their **Design** and **Operating Effectiveness** ratings. - Note the current status of the assessment (e.g., Awaiting Assessment). - Do not include any empty or irrelevant fields. Input: {objectJson} Provide the executive summary in a short, readable paragraph of 5 sentences or less that could be shared with senior management or stakeholders. Generate only the executive summary with no other information or decorators (for example, \"here is the executive summary\" at the start or tags such as <|end_of_text|>). Do not repeat information and be succinct. Suggest anything that you believe, as an expert risk professional, that requires attention. Output:","title":"Develop and Deploy Prompt"},{"location":"chapter4/3_prompt/#lab-33-develop-and-deploy-prompt","text":"Now knowing the exact input type, we can create a prompt for our desired output.","title":"Lab 3.3: Develop and Deploy Prompt"},{"location":"chapter4/3_prompt/#1-set-up-and-deploy-the-prompt-in-prompt-lab","text":"As per Lab 1.1, develop and deploy the prompt. The only difference is the input data will be the json object we identified in the last step, and the prompt template variable must be objectJson Here is an example prompt: You are a compliance and risk expert writing an executive summary for a third-party qualitative risk assessment. Given the following JSON input (representing a risk assessment in OpenPages), summarize the key information in professional business language. Your summary should: - Begin with a brief description of the purpose of the risk assessment. - Mention the assessment type (e.g., Third Party, Qualitative), assessor, and reviewer. - Highlight the assessment period and frequency. - Summarize how many direct risks were identified, and break them down by their **Inherent** and **Residual Risk Ratings** (e.g., how many were High, Medium, Low, Very High). - Identify any particularly critical risks (e.g., High Inherent AND High Residual). - Include a high-level overview of the control environment: how many controls are mapped, and summarize their **Design** and **Operating Effectiveness** ratings. - Note the current status of the assessment (e.g., Awaiting Assessment). - Do not include any empty or irrelevant fields. Input: {objectJson} Provide the executive summary in a short, readable paragraph of 5 sentences or less that could be shared with senior management or stakeholders. Generate only the executive summary with no other information or decorators (for example, \"here is the executive summary\" at the start or tags such as <|end_of_text|>). Do not repeat information and be succinct. Suggest anything that you believe, as an expert risk professional, that requires attention. Output:","title":"1. Set Up and Deploy the prompt in Prompt Lab"},{"location":"chapter4/4_integrate/","text":"Lab 3.4: Integrate ML Model and Make Available in View After deploying the model, the last remaining step is integrating the ML model and making it available in the view we want to interact with it in. 1. Integrating Deployed AI Model to OpenPages As with Step 3 in Lab 3.2, integrate your deployed ML model with a view input. The only difference is we want to having meaningful outputs. For Outputs , select Insight type as Set fields and select a single insight. For the example prompt we are using, the JSONata string will just be results[0].generated_text . The Target field is Executive Summary (Demo-RA:Executive Summary) . Add a suitable description and customise the style to your choosing in Guidance . Save the model. 2. Add the Model to a View As with step 4 in Lab 3.2, add the new model to the relevant object view (Risk Assessment) and publish. 5. Test the Model in OpenPages Find an example Risk Assessment, and run the new Executive Summary Model in the area you placed in the previous step.","title":"Integrate ML Model and Make Available in View"},{"location":"chapter4/4_integrate/#lab-34-integrate-ml-model-and-make-available-in-view","text":"After deploying the model, the last remaining step is integrating the ML model and making it available in the view we want to interact with it in.","title":"Lab 3.4: Integrate ML Model and Make Available in View"},{"location":"chapter4/4_integrate/#1-integrating-deployed-ai-model-to-openpages","text":"As with Step 3 in Lab 3.2, integrate your deployed ML model with a view input. The only difference is we want to having meaningful outputs. For Outputs , select Insight type as Set fields and select a single insight. For the example prompt we are using, the JSONata string will just be results[0].generated_text . The Target field is Executive Summary (Demo-RA:Executive Summary) . Add a suitable description and customise the style to your choosing in Guidance . Save the model.","title":"1. Integrating Deployed AI Model to OpenPages"},{"location":"chapter4/4_integrate/#2-add-the-model-to-a-view","text":"As with step 4 in Lab 3.2, add the new model to the relevant object view (Risk Assessment) and publish.","title":"2. Add the Model to a View"},{"location":"chapter4/4_integrate/#5-test-the-model-in-openpages","text":"Find an example Risk Assessment, and run the new Executive Summary Model in the area you placed in the previous step.","title":"5. Test the Model in OpenPages"}]}